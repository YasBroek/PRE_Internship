# 2025-07-15

- Tried training with Projected Gradient Descent
- Compared training function using sigma, PGD and relu to prioritized planning with original weights: still worse
- Created overleaf for report
- Starting thinking about questions for report


- What are the scientific questions I want to contribute to?
    - How can we use ML to improve MAPF algorithms that already exist?
    - How can we apply gradient descent to the MAPF problem if most of the known algorithms are non-differentiable?
    - Can we use learning from a training set of high-quality MAPF solutions to guide generalization to unseen problem instances?
    - How effective is the use of perturbation-based approaches (e.g., Fenchel-Young losses) to enable learning in a structured, combinatorial setting like MAPF?
- What's different from prior studies?
    - We apply Fenchel-Young loss frameworks to enable backpropagation through a discrete MAPF optimization process.
    - We focus on learning parameters (weights) that influence the solver outcome, without modifying the solver itself.
    - We apply a Decision-Focused learning approach in which we aim to optimize the cost function
- What are my contributions?
    - Proposing a novel framework to integrate MAPF solvers with machine learning via implicit differentiation and perturbation-based methods
    - Applying Fenchel-Young losses to learn parameters
    - Designing experiments that demonstrate how learning from optimal or near-optimal solutions can improve solver performance on new instances.
    - Providing an empirical comparison of models trained with perturbation-based gradients vs. baselines (uniform weights).
- How do I back it up with experiments?
    - Compare results between prioritized planning with and without learnt parameters